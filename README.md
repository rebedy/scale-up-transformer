# scale-up-transformer

This repository contains the early study and code for the paper "[UniXGen: A Unified Vision-Language Model for Multi-View Chest X-ray Generation and Report Generation.](https://openreview.net/pdf?id=xVNY6Th44d)" by Hyungyung Lee, <u>Da Young Lee</u>, Wonjae Kim, Jin-Hwa Kim, Tackeun Kim, Jihang Kim, Leonard Sunwoo5, Edward Cho.

<img src="img/sut.png" width="500px"></img>

This research is based on <a href="https://arxiv.org/abs/2009.14794">Performer</a>, a linear attention-based transformer variant with a **F**ast **A**ttention **V**ia positive **O**rthogonal **R**andom features approach (FAVOR+).


<img src="img/favor+.png" width="500px"></img>


## Citations

```bibtex
@article{kim2023unixgen,
  title={UniXGen: A Unified Vision-Language Model for Multi-View Chest X-ray Generation and Report Generation},
  author={Lee, Hyungyung and Lee, Da Young and Kim, Wonjae and Kim, Jin-Hwa and Kim, Tackeun and Kim, Jihang and Sunwoo, Leonard and Choi, Edward},
  journal={arXiv preprint arXiv:2302.12172},
  year={2023}
}
```

```bibtex
@misc{choromanski2020rethinking,
    title   = {Rethinking Attention with Performers},
    author  = {Krzysztof Choromanski and Valerii Likhosherstov and David Dohan and Xingyou Song and Andreea Gane and Tamas Sarlos and Peter Hawkins and Jared Davis and Afroz Mohiuddin and Lukasz Kaiser and David Belanger and Lucy Colwell and Adrian Weller},
    year    = {2020},
    eprint  = {2009.14794},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}
```
